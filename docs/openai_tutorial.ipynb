{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac016d2-6a41-47cb-9e6c-515691613bf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 🧠 Introduction to Automated Data Extraction from SEC Filings with Python and OpenAI\n",
    "Welcome to this hands-on coding tutorial designed for research fellows who are new to Python programming and AI-driven data extraction. In this notebook, we will walk through how to write a Python script that leverages large language models to extract structured information from **SEC Form 3 filings**, a common document in finance and regulatory research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07410a0b-85bf-4da7-bf80-c479b29b49f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 🎯 Objective\n",
    "Our goal is to automatically extract key details such as the insider’s name, their role(s), company information, and the filing date from a raw Form 3 text file. We’ll use OpenAI’s API to interpret unstructured text, and validate the results using a strict schema defined with Python’s pydantic library.\n",
    "\n",
    "## 🛠️ What You'll Learn\n",
    "This notebook will help you:\n",
    "\n",
    "- Load and read a raw SEC filing text file.\n",
    "\n",
    "- Securely access API keys using environment variables.\n",
    "\n",
    "- Use the openai Python client to make structured API calls.\n",
    "\n",
    "- Define and validate response schemas using pydantic.\n",
    "\n",
    "- Build system prompts to guide a language model for information extraction.\n",
    "\n",
    "- Parse and handle structured responses from a language model.\n",
    "\n",
    "## 📦 Key Python Concepts Covered\n",
    "- **File handling:** Reading text data from a file.\n",
    "\n",
    "- **Environment management:** Loading sensitive credentials with dotenv.\n",
    "\n",
    "- **API usage:** Sending structured requests to OpenAI's language models.\n",
    "\n",
    "- **Data validation:** Using pydantic to enforce structured output.\n",
    "\n",
    "- **Typing and classes:** Building robust and type-safe data models.\n",
    "\n",
    "## 📄 About SEC Form 3\n",
    "Form 3 is a statement of beneficial ownership filed with the U.S. Securities and Exchange Commission (SEC). It discloses who owns what stake in a publicly traded company, typically corporate insiders such as directors, officers, and large shareholders. These forms are important for legal compliance, research, and transparency.\n",
    "\n",
    "## 💡 Why Use Language Models?\n",
    "SEC filings are often written in inconsistent formats, mixing structured XML and freeform text. Traditional parsers struggle with this ambiguity. By using a language model, we can extract structured fields from messy text without writing dozens of custom rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7165d76-2946-4e50-b9ee-772f6363a9f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 📓 Jupyter Notebook Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d31c6-6e88-423c-bea6-5a0fa98d8a3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ▶️ Running Code\n",
    "- **Shift + Enter**: Run the current cell and move to the next\n",
    "- **Ctrl + Enter**: Run the current cell and stay there\n",
    "- **Alt + Enter**: Run current cell and insert a new one below\n",
    "\n",
    "---\n",
    "\n",
    "### ➕ Adding / Deleting Cells\n",
    "- **A**: Add cell above (in command mode)\n",
    "- **B**: Add cell below\n",
    "- **D, D**: Delete cell (press 'D' twice)\n",
    "- **M**: Convert to Markdown\n",
    "- **Y**: Convert to Code\n",
    "\n",
    "(Ensure you're in **Command Mode** — press `Esc` if unsure)\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Markdown Basics (for text cells)\n",
    "- `# Header 1`, `## Header 2`, etc.\n",
    "- `**bold**`, `_italic_`, `code` (inline)\n",
    "- Triple backticks (```) for code blocks\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 Tips\n",
    "- Use `Tab` for autocompletion\n",
    "- Use `Shift + Tab` for docstrings and help\n",
    "- Interrupt a long-running cell: **Kernel → Interrupt**\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Restarting / Resetting\n",
    "- **Restart Kernel**: Clears memory & variables (under Kernel menu)\n",
    "- Useful if things break or slow down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5af751-fc07-4e71-ad27-ddeebb06a76d",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "\n",
    "In Python, it's good practice to keep all your imports in one place — typically at the **top of the notebook or script**. This makes it easier to see what libraries are required and helps avoid unexpected bugs or missing dependencies.\n",
    "\n",
    "That said, there are different styles:\n",
    "- Some developers (including NVIDIA's ML lead!) prefer importing libraries *right before they use them*, to make each section more self-contained.\n",
    "- Others (like me) prefer importing everything at the top for **clarity and reproducibility**.\n",
    "\n",
    "👉 **There’s no strict rule — choose the style that helps you and your team stay organized.** For this tutorial, we’ll put them all at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3bf1bd-c675-46a8-afde-dd7809d2eb9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66be60-88e4-4098-9dcf-d6b46da4f084",
   "metadata": {},
   "source": [
    "# Config\n",
    "\n",
    "This section stores configuration variables, values that do not change during the program’s execution, such as file paths, model names, and environment settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336f5e34-f8c8-4f76-be25-532b47d468a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to your filing\n",
    "filing_path = \"/zfs/data/NODR/EDGAR_HTTPS/edgar/data/1656998/0000950103-24-000077.txt\"\n",
    "\n",
    "# Loading your environment variables this should return True\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b81237-0ac2-4a44-8209-3655a8b4c918",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **Oh no!** Why is this False?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121602a-a7e4-4543-a99f-4bf41af1e238",
   "metadata": {},
   "source": [
    "# Exercise 1: Handling Private keys and variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f68552-7642-4bb6-9a48-0bfb5177b3f4",
   "metadata": {},
   "source": [
    "1. Create an .env file\n",
    "2. modify the .env file to include OPENAI_API_KEY='The given key'\n",
    "3. retry load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c18f5f-91b7-443a-944f-fadae5acc1b7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>1. Hint</summary>\n",
    "  Try using the bash command touch .env to create a new \n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>2. Hint</summary>\n",
    "  Either modify with your favorite text editor or attempt to edit in jupyterhub, raise a red card if you need help\n",
    "</details>\n",
    "<details>\n",
    "  <summary>3. Hint</summary>\n",
    "  re-run the config cell or copy it and try again!\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5c9d9-e8a2-4442-9fa5-d2689551edc6",
   "metadata": {},
   "source": [
    "### creating the client\n",
    "\n",
    "Need to speak a little more about clients and servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82aff1a5-6530-4876-8d3e-21781f18582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d92ad1-5025-4b7e-bf27-5fa488b33e5b",
   "metadata": {},
   "source": [
    "# Exercise 2: Shaping up LLMs for Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace5a21-1d7f-4700-9ccf-e4795de79663",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LLM Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece5d03-c33d-4091-a8f8-e63208ed235d",
   "metadata": {},
   "source": [
    "#### 🧠 OpenAI API Prompting Cheat Sheet\n",
    "\n",
    "**System Prompt**  \n",
    "Sets behavior or persona. Use once at the start.  \n",
    "➡️ `\"You are a helpful scientific assistant.\"`\n",
    "\n",
    "**User Prompt**  \n",
    "The user's question or task. Can appear multiple times.  \n",
    "➡️ `\"Explain how Python virtual environments work.\"`\n",
    "\n",
    "**Templates**  \n",
    "Reusable prompt formats with variables. One for inputs: \n",
    "Example:  \n",
    "```python\n",
    "f'''\n",
    "You are an assistant.\n",
    "\n",
    "\n",
    "Context: {{context}} \n",
    "Question: {{question}} \n",
    "Answer:\n",
    "'''\n",
    "\n",
    "```\n",
    "one for ouputs\n",
    "\n",
    "```python\n",
    "'''\n",
    "Please return the following json:\n",
    "{{company_name: comp_name\n",
    "mission_statement: \"We like to do business \"\n",
    "\n",
    "}}'''\n",
    "\n",
    "```\n",
    "**Temperature**  \n",
    "Controls randomness in output.  \n",
    "- `0.0` → Deterministic (use for logic, code)  \n",
    "- `0.5` → Balanced  \n",
    "- `1.0+` → Creative, varied  \n",
    "\n",
    "**Example API Call (Python)**  \n",
    "```python\n",
    "openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  temperature=0.2,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a concise Python tutor.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I create a virtual environment?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7206ef-462e-494b-9d2b-e3adf59df990",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa1108-66f5-4405-b70f-51c52fbd795a",
   "metadata": {},
   "source": [
    "Extract key information from a Form 3 filing, including the insider’s name, their role(s), the company name, CIK, and filing date — and return it in a structured, standardized format (e.g., JSON or dictionary).\n",
    "\n",
    "This will make the data easy to validate, analyze, and store for downstream use (like building a dataset or running queries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3a1b9-32da-4767-a232-1443f2827ad8",
   "metadata": {},
   "source": [
    "#### Develop a system prompt to help pull this information from the Form 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46283c54-bed4-4acf-804f-75661593b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt='Write your prompt here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877a2e7-cd30-405e-90fc-290a02a3915d",
   "metadata": {},
   "source": [
    "#### Get the text from the filing to be the user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e0e00dc-016b-44f6-9750-a415a1e79614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text from the file path\n",
    "# with open(...,'r') as f\n",
    "# Write the code here\n",
    "\n",
    "filing_text=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b59429-e446-4cc9-93fb-0f4f1c9ee659",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt=filing_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701ea2f-12c0-4a93-b388-0e858429be55",
   "metadata": {},
   "source": [
    "#### Finally use OpenAI built in help pydantic to structure the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec16e785-ba7c-4b49-96a9-2f294d4dbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Form3Filing(BaseModel):\n",
    "    insider_name:str\n",
    "    #....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4edbf6-7ba6-4898-a1f5-6dd481652a73",
   "metadata": {},
   "source": [
    "#### Call the Api without structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96644038-dc94-49ec-87f5-261652afd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.parse(\n",
    "    model=\"o4-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4447e-25f5-423b-ad84-82da7ae054fa",
   "metadata": {},
   "source": [
    "### Understand the Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d399cfba-3112-4ccf-9171-01eb18b4e276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedResponse[NoneType](id='resp_685475c8ef3481a2b3abdb576d121d940da816bcc5cf2279', created_at=1750365640.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='o4-mini-2025-04-16', object='response', output=[ResponseReasoningItem(id='rs_685475c97c5481a2a126e442be7713160da816bcc5cf2279', summary=[], type='reasoning', encrypted_content=None, status=None), ParsedResponseOutputMessage[NoneType](id='msg_685475cb078481a2a2e4060a9fd420450da816bcc5cf2279', content=[ParsedResponseOutputText[NoneType](annotations=[], text='Hello! It seems there’s no question or request. How can I assist you today?', type='output_text', logprobs=None, parsed=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=14, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=216, output_tokens_details=OutputTokensDetails(reasoning_tokens=192), total_tokens=230), user=None, max_tool_calls=None, store=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933a5f6-d6ac-439f-a194-c1e820ddf17b",
   "metadata": {},
   "source": [
    "### Call the API with Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a9c1f5e-983a-4e94-b5da-182c7a28533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.parse(\n",
    "    model=\"o4-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    text_format=Form3Filing,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46d138f6-75ac-4930-81f9-59d129469baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insider_name': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_parsed.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f2570-4b9d-452a-94fd-4d6edcbf4dcd",
   "metadata": {},
   "source": [
    "# Exercise 3: Development\n",
    "\n",
    "Put everything into a py file and run it from the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41234f7-cb28-436e-ad81-9ebb3bb7b9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
